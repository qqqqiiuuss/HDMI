# TWIST Teacher Training å®Œæ•´ç§»æ¤åˆ° HDMI æŒ‡å—

**ç›®æ ‡**: åœ¨ HDMI æ¡†æ¶ä¸­å®Œæ•´å®ç° `bash train_teacher.sh 0927_twist_teacher cuda:0` çš„å…¨éƒ¨åŠŸèƒ½

---

## ç›®å½•
1. [æ ¸å¿ƒå·®å¼‚åˆ†æ](#1-æ ¸å¿ƒå·®å¼‚åˆ†æ)
2. [TWIST Teacher è®­ç»ƒæµç¨‹è§£æ](#2-twist-teacher-è®­ç»ƒæµç¨‹è§£æ)
3. [HDMI æ¡†æ¶é€‚é…æ–¹æ¡ˆ](#3-hdmi-æ¡†æ¶é€‚é…æ–¹æ¡ˆ)
4. [è¯¦ç»†ä¿®æ”¹æ­¥éª¤](#4-è¯¦ç»†ä¿®æ”¹æ­¥éª¤)
5. [é…ç½®æ–‡ä»¶å¯¹ç…§](#5-é…ç½®æ–‡ä»¶å¯¹ç…§)
6. [å®Œæ•´ä»£ç ç¤ºä¾‹](#6-å®Œæ•´ä»£ç ç¤ºä¾‹)
7. [æµ‹è¯•éªŒè¯](#7-æµ‹è¯•éªŒè¯)

---

## 1. æ ¸å¿ƒå·®å¼‚åˆ†æ

### 1.1 è®­ç»ƒæµç¨‹å¯¹æ¯”

| ç‰¹æ€§ | TWIST (`g1_priv_mimic`) | HDMI (`G1/hdmi/move_suitcase`) |
|-----|------------------------|-------------------------------|
| **ç¯å¢ƒ** | IsaacGym | IsaacLab |
| **Motion æ•°æ®** | MotionLib (pkl) | MotionDataset (npz) |
| **ç®—æ³•** | PPO + Distillation | PPO-ROA (Teacher-Student) |
| **è§‚å¯Ÿç©ºé—´** | å›ºå®šç»“æ„ | æ¨¡å—åŒ– MDP |
| **å¥–åŠ±å‡½æ•°** | ç¡¬ç¼–ç ç±»æ–¹æ³• | é…ç½®é©±åŠ¨ |
| **ç‰¹æƒä¿¡æ¯** | æ‰‹åŠ¨æ‹¼æ¥ | è‡ªåŠ¨ç¼–ç  |
| **History** | æ‰‹åŠ¨ç®¡ç† Buffer | è‡ªåŠ¨ History æœºåˆ¶ |

---

### 1.2 è§‚å¯Ÿç©ºé—´å¯¹æ¯”

#### **TWIST è§‚å¯Ÿç©ºé—´** (`g1_mimic_distill_config.py:16-25`)

```python
# æ€»è§‚å¯Ÿç»´åº¦è®¡ç®—
num_actions = 23
tar_obs_steps = [1, 5, 10, 15, ..., 95]  # 20 ä¸ªæœªæ¥æ­¥

# 1. Proprio (æœ¬ä½“æ„Ÿè§‰)
n_proprio = 3 + 2 + 3*num_actions  # 80
# = base_lin_vel(3) + base_ang_vel(2) + dof_pos(23) + dof_vel(23) + action(23)

# 2. Mimic Obs (è¿åŠ¨è·Ÿè¸ªè§‚å¯Ÿ)
n_priv_mimic_obs = len(tar_obs_steps) * (8 + num_actions + 3*9)  # 20 * (8 + 23 + 27) = 1160
# = 20æ­¥ Ã— [root_pos(3) + root_rot(3) + root_lin_vel(2) + ref_dof_pos(23) + 9ä¸ªå…³é”®ç‚¹ä½ç½®(3Ã—9)]

# 3. Priv Info (ç‰¹æƒä¿¡æ¯ - Teacher only)
n_priv_info = 3 + 1 + 3*9 + 2 + 4 + 1 + 2*num_actions  # 85
# = base_lin_vel(3) + root_height(1) + key_body_pos(27) + contact_mask(2) + priv_latent(4) + ???(1) + ???(46)

# Total = 80 + 1160 + 85 = 1325
```

**å…³é”®ç‰¹å¾**:
- âœ… ä½¿ç”¨ **å¤šä¸ªæœªæ¥æ­¥** (20 ä¸ªæ—¶é—´æ­¥) çš„å‚è€ƒè¿åŠ¨
- âœ… åŒ…å« **9 ä¸ªå…³é”®ç‚¹** çš„å±€éƒ¨ä½ç½®
- âœ… **ç‰¹æƒä¿¡æ¯** åŒ…å«çœŸå®çš„æ¥è§¦çŠ¶æ€ã€åœ°å½¢é«˜åº¦ç­‰

---

#### **HDMI è§‚å¯Ÿç©ºé—´** (æ¨¡å—åŒ–)

```yaml
# cfg/task/G1/hdmi/move_suitcase.yaml
observation:
  policy_obs:
    command(Command): null
    robot_state(RobotState):
      joint_names: [".*"]
    ref_tracking(ReferenceTracking):
      num_future_steps: 4  # ä¸ TWIST ä¸åŒï¼
      body_names: [".*ankle.*", ".*wrist.*"]

  # Teacher ä¸“ç”¨
  critic_obs:
    command(Command): null
    robot_state(RobotState): ...
    privileged_terrain(PrivilegedTerrain): null
```

**å…³é”®å·®å¼‚**:
- âŒ HDMI é»˜è®¤åªç”¨ **4 ä¸ªæœªæ¥æ­¥**ï¼ŒTWIST ç”¨ **20 ä¸ª**
- âŒ HDMI çš„è§‚å¯Ÿæ˜¯**æ¨¡å—åŒ–ç»„åˆ**ï¼ŒTWIST æ˜¯**å›ºå®šæ‹¼æ¥**
- âŒ HDMI ç¼ºå°‘ TWIST çš„ **å…³é”®ç‚¹è¿½è¸ª**

---

### 1.3 å¥–åŠ±å‡½æ•°å¯¹æ¯”

#### **TWIST å¥–åŠ±å‡½æ•°** (`g1_mimic_distill_config.py:167-242`)

```python
rewards:
  scales:
    tracking_joint_dof = 0.6      # DOF ä½ç½®è·Ÿè¸ª
    tracking_joint_vel = 0.2      # DOF é€Ÿåº¦è·Ÿè¸ª
    tracking_root_pose = 0.6      # æ ¹å§¿æ€è·Ÿè¸ª
    tracking_root_vel = 1.0       # æ ¹é€Ÿåº¦è·Ÿè¸ª
    tracking_keybody_pos = 2.0    # å…³é”®ç‚¹ä½ç½®è·Ÿè¸ª (æœ€é‡è¦!)

    feet_slip = -0.1              # è„šæ»‘åŠ¨æƒ©ç½š
    feet_contact_forces = -5e-4   # æ¥è§¦åŠ›æƒ©ç½š
    feet_stumble = -1.25          # ç»Šå€’æƒ©ç½š
    feet_air_time = 5.0           # ç©ºä¸­æ—¶é—´å¥–åŠ±

    dof_pos_limits = -5.0         # å…³èŠ‚é™ä½æƒ©ç½š
    dof_vel = -1e-4               # é€Ÿåº¦æ­£åˆ™åŒ–
    dof_acc = -5e-8               # åŠ é€Ÿåº¦æ­£åˆ™åŒ–
    action_rate = -0.01           # åŠ¨ä½œå˜åŒ–ç‡æƒ©ç½š
```

**æ ¸å¿ƒç‰¹å¾**:
- ğŸ¯ **å…³é”®ç‚¹è·Ÿè¸ª** (`tracking_keybody_pos = 2.0`) æƒé‡æœ€é«˜
- ğŸ¯ ä½¿ç”¨ **Gaussian æ ¸** è®¡ç®—è·Ÿè¸ªè¯¯å·®: `exp(-err^2 / (2*sigma^2))`
- ğŸ¯ åŒ…å«ä¸°å¯Œçš„**æ­£åˆ™åŒ–é¡¹**ï¼ˆé€Ÿåº¦ã€åŠ é€Ÿåº¦ã€åŠ¨ä½œå˜åŒ–ç‡ï¼‰

---

#### **HDMI å¥–åŠ±å‡½æ•°** (æ¨¡å—åŒ–)

```yaml
# cfg/task/G1/hdmi/move_suitcase.yaml
reward:
  tracking_reward:
    body_position_tracking(BodyPositionTracking):
      weight: 1.0
      body_names: [".*ankle.*"]
    joint_position_tracking(JointPositionTracking):
      weight: 0.5

  regularization:
    action_rate(ActionRate):
      weight: -0.01
```

**æ ¸å¿ƒå·®å¼‚**:
- âŒ HDMI ç¼ºå°‘ TWIST çš„ **å…³é”®ç‚¹è·Ÿè¸ª** å¥–åŠ±
- âŒ HDMI ç¼ºå°‘ **è„šéƒ¨ç©ºä¸­æ—¶é—´** å¥–åŠ±
- âŒ HDMI çš„å¥–åŠ±é¡¹**ä¸å¤Ÿä¸°å¯Œ**

---

### 1.4 ç½‘ç»œæ¶æ„å¯¹æ¯”

#### **TWIST Teacher ç½‘ç»œ**

```python
# legged_gym/gym_utils/rl/ppo/actor_critic.py (TWIST ä½¿ç”¨çš„)
class ActorCritic:
    def __init__(self):
        # Actor (Policy)
        self.actor = MLP(
            input_size=n_proprio + n_priv_mimic_obs,  # ä¸åŒ…å« priv_info
            output_size=num_actions,
            hidden_sizes=[512, 256, 128],
            activation=nn.ELU()
        )

        # Critic (Value function)
        self.critic = MLP(
            input_size=n_proprio + n_priv_mimic_obs + n_priv_info,  # åŒ…å«ç‰¹æƒä¿¡æ¯
            output_size=1,
            hidden_sizes=[512, 256, 128],
            activation=nn.ELU()
        )
```

**ç‰¹å¾**:
- âœ… Actor åªä½¿ç”¨ **æœ¬ä½“æ„Ÿè§‰ + å‚è€ƒè¿åŠ¨**
- âœ… Critic é¢å¤–ä½¿ç”¨ **ç‰¹æƒä¿¡æ¯** (åœ°å½¢ã€æ¥è§¦ã€çœŸå®çŠ¶æ€)
- âœ… ä½¿ç”¨ **ELU æ¿€æ´»å‡½æ•°**

---

#### **HDMI PPO-ROA ç½‘ç»œ** (`active_adaptation/learning/ppo/ppo_roa.py`)

```python
class PPO_ROA:
    def __init__(self):
        # Teacher phase
        self.encoder_priv = MLP(...)  # ç¼–ç ç‰¹æƒä¿¡æ¯ â†’ latent
        self.actor = MLP(...)          # ç­–ç•¥ç½‘ç»œ
        self.critic = MLP(...)         # ä»·å€¼ç½‘ç»œ

        # Student phase
        self.adapt_module = MLP/GRU(...) # ä»å†å²æ¨æ–­ latent
        self.actor_adapt = self.actor    # å…±äº«ç­–ç•¥ç½‘ç»œ
```

**æ ¸å¿ƒå·®å¼‚**:
- âœ… HDMI æœ‰ **æ˜¾å¼çš„ latent ç¼–ç å™¨**
- âœ… HDMI æœ‰ **adaptation module** (student ç”¨)
- âŒ HDMI çš„ Teacher è®­ç»ƒ**ä¹Ÿéœ€è¦ adaptation module**

---

## 2. TWIST Teacher è®­ç»ƒæµç¨‹è§£æ

### 2.1 è®­ç»ƒå‘½ä»¤è§£æ

```bash
bash train_teacher.sh 0927_twist_teacher cuda:0
```

**å®é™…æ‰§è¡Œ**:
```python
python train.py \
    --task "g1_priv_mimic" \
    --proj_name "g1_priv_mimic" \
    --exptid "0927_twist_teacher" \
    --device "cuda:0"
```

---

### 2.2 å…³é”®è®­ç»ƒå‚æ•° (`g1_mimic_distill_config.py`)

```python
class G1MimicPrivCfg:
    class env:
        num_envs = 4096                    # å¹¶è¡Œç¯å¢ƒæ•°
        episode_length_s = 10              # æ¯ä¸ª episode 10 ç§’
        obs_type = 'priv'                  # Teacher æ¨¡å¼

        # æœªæ¥è§‚å¯Ÿæ­¥æ•° (æ ¸å¿ƒ!)
        tar_obs_steps = [1, 5, 10, ..., 95]  # 20 ä¸ªæ­¥

        # å…³é”®ç‚¹ (9 ä¸ª)
        key_bodies = [
            "left_rubber_hand", "right_rubber_hand",
            "left_ankle_roll_link", "right_ankle_roll_link",
            "left_knee_link", "right_knee_link",
            "left_elbow_link", "right_elbow_link",
            "head_mocap"
        ]

    class sim:
        dt = 0.002        # ç‰©ç†æ­¥é•¿ 2ms
        decimation = 10   # åŠ¨ä½œé¢‘ç‡ 50Hz

    class rewards:
        tracking_sigma = 0.2         # Gaussian æ ¸æ ‡å‡†å·®
        tracking_sigma_ang = 0.125   # è§’åº¦ Gaussian æ ‡å‡†å·®
```

---

### 2.3 Motion æ•°æ®é…ç½®

```yaml
# TWIST ä½¿ç”¨: legged_gym/motion_data_configs/twist_dataset.yaml
root_path: "/path/to/motions"
motions:
  - file: "walk.pkl"
    weight: 1.0
    difficulty: 0
    description: "Walking forward"
```

**Motion æ•°æ®æ ¼å¼** (pkl):
```python
motion_data = {
    "fps": 50,
    "root_pos": (T, 3),
    "root_rot": (T, 4),
    "dof_pos": (T, 23),
    "local_body_pos": (T, 9, 3),  # 9 ä¸ªå…³é”®ç‚¹çš„å±€éƒ¨ä½ç½®
}
```

---

## 3. HDMI æ¡†æ¶é€‚é…æ–¹æ¡ˆ

### 3.1 æ€»ä½“ç­–ç•¥

æˆ‘ä»¬é‡‡ç”¨ **åˆ†å±‚é€‚é…** ç­–ç•¥ï¼š

```
Layer 1: Motion Data      â†’ ä½¿ç”¨ TwistMotionDataset (å·²å®Œæˆ)
Layer 2: Observations     â†’ åˆ›å»º TWIST é£æ ¼çš„è§‚å¯Ÿå‡½æ•°
Layer 3: Rewards          â†’ åˆ›å»º TWIST é£æ ¼çš„å¥–åŠ±å‡½æ•°
Layer 4: Command          â†’ æ‰©å±• RobotTracking æ”¯æŒ 20 ä¸ªæœªæ¥æ­¥
Layer 5: Task Config      â†’ åˆ›å»ºå®Œæ•´çš„ TWIST ä»»åŠ¡é…ç½®
```

---

### 3.2 éœ€è¦åˆ›å»ºçš„æ–°ç»„ä»¶

#### **3.2.1 è§‚å¯Ÿå‡½æ•°** (`active_adaptation/envs/mdp/observations.py`)

éœ€è¦æ·»åŠ ï¼š
1. âœ… `MultiStepReferenceTracking` - 20 ä¸ªæœªæ¥æ­¥çš„å‚è€ƒè¿åŠ¨
2. âœ… `KeyBodyPositionTracking` - 9 ä¸ªå…³é”®ç‚¹è·Ÿè¸ª
3. âœ… `PrivilegedInfo` - ç‰¹æƒä¿¡æ¯ï¼ˆåœ°å½¢ã€æ¥è§¦ç­‰ï¼‰

#### **3.2.2 å¥–åŠ±å‡½æ•°** (`active_adaptation/envs/mdp/rewards.py`)

éœ€è¦æ·»åŠ ï¼š
1. âœ… `KeyBodyPositionTracking` - å…³é”®ç‚¹ä½ç½®å¥–åŠ± (Gaussian æ ¸)
2. âœ… `FeetAirTime` - è„šéƒ¨ç©ºä¸­æ—¶é—´å¥–åŠ±
3. âœ… `FeetStumble` - ç»Šå€’æƒ©ç½š
4. âœ… `RootVelocityTracking` - æ ¹é€Ÿåº¦è·Ÿè¸ª

#### **3.2.3 Command** (`active_adaptation/envs/mdp/commands/hdmi/twist_command.py`)

åˆ›å»ºæ–°çš„ `TwistRobotTracking` ç±»ï¼š
- æ”¯æŒ 20 ä¸ªæœªæ¥æ­¥
- æ”¯æŒ 9 ä¸ªå…³é”®ç‚¹
- ä½¿ç”¨ `TwistMotionDataset`

---

## 4. è¯¦ç»†ä¿®æ”¹æ­¥éª¤

### Step 1: åˆ›å»º TWIST è§‚å¯Ÿå‡½æ•°

åˆ›å»º `active_adaptation/envs/mdp/observations/twist_observations.py`:

```python
import torch
from active_adaptation.envs.mdp.base import Observation

class MultiStepReferenceTracking(Observation):
    """
    å¤šæ­¥å‚è€ƒè¿åŠ¨è·Ÿè¸ªè§‚å¯Ÿ (TWIST é£æ ¼)

    è¾“å‡º: [num_future_steps, (root_pose + root_vel + dof_pos + key_body_pos)]
    """

    def __init__(
        self,
        env,
        num_future_steps: int = 20,  # TWIST é»˜è®¤ 20 æ­¥
        key_body_names: list = None,
        coordinate_frame: str = "root",  # "root" æˆ– "world"
    ):
        super().__init__(env)
        self.num_future_steps = num_future_steps
        self.command_manager = env.command_manager

        # æŸ¥æ‰¾å…³é”®ç‚¹ç´¢å¼•
        if key_body_names is None:
            # TWIST é»˜è®¤ 9 ä¸ªå…³é”®ç‚¹
            key_body_names = [
                ".*left.*hand", ".*right.*hand",
                ".*left.*ankle", ".*right.*ankle",
                ".*left.*knee", ".*right.*knee",
                ".*left.*elbow", ".*right.*elbow",
                ".*head"
            ]

        self.key_body_indices = []
        for pattern in key_body_names:
            indices, _ = self.asset.find_bodies(pattern)
            self.key_body_indices.extend(indices)

        self.num_key_bodies = len(self.key_body_indices)
        self.coordinate_frame = coordinate_frame

    def __call__(self) -> torch.Tensor:
        """
        è¿”å›: [num_envs, num_future_steps * obs_per_step]
        obs_per_step = 8 (root) + num_dof + 3 * num_key_bodies
        """
        # è·å–æœªæ¥å‚è€ƒè¿åŠ¨
        future_ref = self.command_manager.future_ref_motion  # [N, num_steps, ...]

        # æå–å„éƒ¨åˆ†
        root_pos = future_ref.body_pos_w[:, :, 0, :]   # [N, steps, 3]
        root_quat = future_ref.body_quat_w[:, :, 0, :]  # [N, steps, 4]
        root_lin_vel = future_ref.body_lin_vel_w[:, :, 0, :]  # [N, steps, 3]
        root_ang_vel = future_ref.body_ang_vel_w[:, :, 0, :2]  # [N, steps, 2] XY only
        dof_pos = future_ref.joint_pos  # [N, steps, num_dof]
        key_body_pos = future_ref.body_pos_w[:, :, self.key_body_indices, :]  # [N, steps, 9, 3]

        if self.coordinate_frame == "root":
            # è½¬æ¢åˆ°æ ¹åæ ‡ç³»
            robot_root_pos = self.asset.data.root_link_pos_w
            robot_root_quat = self.asset.data.root_link_quat_w

            # ç›¸å¯¹ä½ç½®
            root_pos_rel = root_pos - robot_root_pos.unsqueeze(1)
            root_pos_rel = quat_rotate_inverse(robot_root_quat.unsqueeze(1), root_pos_rel)

            # è½¬æ¢å…³é”®ç‚¹ä½ç½®
            key_body_pos_rel = key_body_pos - robot_root_pos.unsqueeze(1).unsqueeze(2)
            key_body_pos_rel = quat_rotate_inverse(
                robot_root_quat.unsqueeze(1).unsqueeze(2),
                key_body_pos_rel
            )
        else:
            root_pos_rel = root_pos
            key_body_pos_rel = key_body_pos

        # æ‹¼æ¥
        # root_pose: pos(3) + quat(3, å¿½ç•¥ w) + lin_vel(2, XY only) = 8
        root_obs = torch.cat([
            root_pos_rel,
            root_quat[..., 1:],  # å¿½ç•¥ w åˆ†é‡
            root_lin_vel[..., :2]  # åªè¦ XY
        ], dim=-1)  # [N, steps, 8]

        # æ‹¼æ¥æ‰€æœ‰
        obs = torch.cat([
            root_obs,  # [N, steps, 8]
            dof_pos,   # [N, steps, num_dof]
            key_body_pos_rel.flatten(-2, -1)  # [N, steps, 9*3]
        ], dim=-1)  # [N, steps, 8 + num_dof + 27]

        # å±•å¹³æ—¶é—´æ­¥ç»´åº¦
        return obs.flatten(-2, -1)  # [N, steps * (8 + num_dof + 27)]


class PrivilegedInfo(Observation):
    """
    ç‰¹æƒä¿¡æ¯è§‚å¯Ÿ (TWIST é£æ ¼)

    åŒ…å«: base_lin_vel, root_height, key_body_pos, contact_mask, priv_latent
    """

    def __init__(self, env, key_body_names: list = None):
        super().__init__(env)
        # ... å®ç°ç±»ä¼¼ä¸Šé¢
```

---

### Step 2: åˆ›å»º TWIST å¥–åŠ±å‡½æ•°

åˆ›å»º `active_adaptation/envs/mdp/rewards/twist_rewards.py`:

```python
import torch
from active_adaptation.envs.mdp.base import Reward

class KeyBodyPositionTracking(Reward):
    """
    å…³é”®ç‚¹ä½ç½®è·Ÿè¸ªå¥–åŠ± (TWIST æ ¸å¿ƒå¥–åŠ±)

    ä½¿ç”¨ Gaussian æ ¸: r = exp(-err^2 / (2*sigma^2))
    """

    def __init__(
        self,
        env,
        weight: float,
        key_body_names: list = None,
        sigma: float = 0.2,  # TWIST é»˜è®¤
        enabled: bool = True
    ):
        super().__init__(env, weight, enabled)
        self.command_manager = env.command_manager
        self.sigma = sigma

        # æŸ¥æ‰¾å…³é”®ç‚¹ç´¢å¼•
        if key_body_names is None:
            key_body_names = [
                ".*left.*hand", ".*right.*hand",
                ".*left.*ankle", ".*right.*ankle",
                ".*left.*knee", ".*right.*knee",
                ".*left.*elbow", ".*right.*elbow",
                ".*head"
            ]

        self.key_body_indices_robot = []
        self.key_body_indices_ref = []

        for pattern in key_body_names:
            indices_robot, names = self.asset.find_bodies(pattern)
            self.key_body_indices_robot.extend(indices_robot)

            # åœ¨å‚è€ƒ motion ä¸­æŸ¥æ‰¾
            indices_ref = [self.command_manager.dataset.body_names.index(name)
                          for name in names]
            self.key_body_indices_ref.extend(indices_ref)

    def compute(self) -> torch.Tensor:
        """
        è®¡ç®—å…³é”®ç‚¹è·Ÿè¸ªè¯¯å·®

        Returns:
            å¥–åŠ±å¼ é‡ [num_envs, 1]
        """
        # è·å–æœºå™¨äººå½“å‰å…³é”®ç‚¹ä½ç½®
        robot_key_body_pos = self.asset.data.body_link_pos_w[:, self.key_body_indices_robot]

        # è·å–å‚è€ƒå…³é”®ç‚¹ä½ç½® (å½“å‰æ—¶åˆ»)
        ref_key_body_pos = self.command_manager.ref_body_pos_w[:, self.key_body_indices_ref]

        # è®¡ç®—è¯¯å·®
        pos_error = (robot_key_body_pos - ref_key_body_pos).norm(dim=-1)  # [N, num_key_bodies]

        # Gaussian æ ¸
        reward = torch.exp(-pos_error**2 / (2 * self.sigma**2))  # [N, num_key_bodies]

        # å¹³å‡æ‰€æœ‰å…³é”®ç‚¹
        reward = reward.mean(dim=-1, keepdim=True)  # [N, 1]

        return reward, torch.ones_like(reward)  # (reward, count)


class FeetAirTime(Reward):
    """
    è„šéƒ¨ç©ºä¸­æ—¶é—´å¥–åŠ± (TWIST é£æ ¼)

    å¥–åŠ±è„šç¦»åœ°çš„æ—¶é—´
    """

    def __init__(
        self,
        env,
        weight: float,
        feet_names: str = ".*ankle.*",
        target_air_time: float = 0.5,  # TWIST é»˜è®¤
        enabled: bool = True
    ):
        super().__init__(env, weight, enabled)
        self.contact_sensor = env.scene.sensors["contact_forces"]
        self.feet_indices = self.asset.find_bodies(feet_names)[0]
        self.target_air_time = target_air_time

        # è®°å½•ç©ºä¸­æ—¶é—´
        self.air_time = torch.zeros(self.num_envs, len(self.feet_indices), device=self.device)
        self.last_contact = torch.ones(self.num_envs, len(self.feet_indices), device=self.device, dtype=bool)

    def step(self, substep: int):
        """æ¯ä¸ªç‰©ç†æ­¥æ›´æ–°ç©ºä¸­æ—¶é—´"""
        if substep == 0:
            # æ£€æµ‹æ¥è§¦
            contact_forces = self.contact_sensor.data.net_forces_w[:, self.feet_indices, 2]  # Z æ–¹å‘
            is_contact = contact_forces > 1.0  # æ¥è§¦é˜ˆå€¼

            # æ›´æ–°ç©ºä¸­æ—¶é—´
            self.air_time += self.env.physics_dt  # æ‰€æœ‰è„šéƒ½å¢åŠ æ—¶é—´
            self.air_time[is_contact] = 0.0  # æ¥è§¦çš„è„šæ¸…é›¶

    def compute(self) -> torch.Tensor:
        """
        è®¡ç®—ç©ºä¸­æ—¶é—´å¥–åŠ±

        Returns:
            å¥–åŠ±å¼ é‡ [num_envs, 1]
        """
        # å¥–åŠ±æ¥è¿‘ç›®æ ‡ç©ºä¸­æ—¶é—´çš„è„š
        reward = torch.clamp(
            self.target_air_time - torch.abs(self.air_time - self.target_air_time),
            min=0.0
        )  # [N, num_feet]

        # å¹³å‡æ‰€æœ‰è„š
        reward = reward.mean(dim=-1, keepdim=True)  # [N, 1]

        return reward, torch.ones_like(reward)


# æ›´å¤šå¥–åŠ±å‡½æ•°...
class RootVelocityTracking(Reward):
    """æ ¹é€Ÿåº¦è·Ÿè¸ªå¥–åŠ±"""
    # ... å®ç°

class FeetStumble(Reward):
    """ç»Šå€’æƒ©ç½š"""
    # ... å®ç°
```

---

### Step 3: æ‰©å±• Command æ”¯æŒ 20 ä¸ªæœªæ¥æ­¥

ä¿®æ”¹ `active_adaptation/envs/mdp/commands/hdmi/command.py`:

```python
class RobotTracking(Command):
    def __init__(
        self,
        env,
        data_path: str,
        future_steps: List[int] = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45,
                                     50, 55, 60, 65, 70, 75, 80, 85, 90, 95],  # TWIST é»˜è®¤
        use_twist_motion: bool = False,
        **kwargs
    ):
        super().__init__(env)

        # æ ¹æ®é…ç½®é€‰æ‹© dataset
        if use_twist_motion or data_path.endswith('.yaml'):
            from active_adaptation.utils.twist_motion import TwistMotionDataset
            self.dataset = TwistMotionDataset.create_from_yaml(
                yaml_path=data_path,
                device=self.device,
                smooth_window=19
            ).to(self.device)
        else:
            self.dataset = MotionDataset.create_from_path(...)

        # æœªæ¥æ­¥æ•° (TWIST ä½¿ç”¨ 20 ä¸ª)
        self.future_steps = torch.tensor(future_steps, device=self.device)

        # ... å…¶ä½™ä»£ç 
```

---

### Step 4: åˆ›å»º TWIST ä»»åŠ¡é…ç½®

åˆ›å»º `cfg/task/G1/hdmi/twist/twist_teacher.yaml`:

```yaml
defaults:
  - /task/G1/hdmi/base/hdmi-base
  - _self_

# ==================== Environment ====================
max_episode_length: 500  # 10s @ 50Hz

# ==================== Command ====================
command:
  _target_: active_adaptation.envs.mdp.commands.hdmi.command.RobotTracking
  data_path: "config/twist_motions.yaml"  # TWIST motion data

  tracking_keypoint_names:
    - ".*left.*hand"
    - ".*right.*hand"
    - ".*left.*ankle"
    - ".*right.*ankle"
    - ".*left.*knee"
    - ".*right.*knee"
    - ".*left.*elbow"
    - ".*right.*elbow"
    - ".*head"

  tracking_joint_names: [".*"]
  root_body_name: "pelvis"

  # TWIST é£æ ¼é…ç½®
  future_steps: [1, 5, 10, 15, 20, 25, 30, 35, 40, 45,
                 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]  # 20 steps

  reset_range: null  # éšæœºèµ·å§‹æ—¶é—´
  sample_motion: true
  use_twist_motion: true

# ==================== Observations ====================
observation:
  policy_obs:  # Actor è¾“å…¥
    proprio(RobotState):
      joint_names: [".*"]
      include_velocity: true
      include_last_action: true

    multi_step_reference(MultiStepReferenceTracking):
      num_future_steps: 20
      key_body_names: [".*left.*hand", ".*right.*hand", ".*ankle", ".*knee", ".*elbow", ".*head"]
      coordinate_frame: "root"

  critic_obs:  # Critic è¾“å…¥ (åŒ…å«ç‰¹æƒä¿¡æ¯)
    proprio(RobotState):
      joint_names: [".*"]
      include_velocity: true
      include_last_action: true

    multi_step_reference(MultiStepReferenceTracking):
      num_future_steps: 20
      key_body_names: [".*left.*hand", ".*right.*hand", ".*ankle", ".*knee", ".*elbow", ".*head"]
      coordinate_frame: "root"

    privileged_info(PrivilegedInfo):
      key_body_names: [".*left.*hand", ".*right.*hand", ".*ankle", ".*knee", ".*elbow", ".*head"]

# ==================== Rewards ====================
reward:
  _mult_dt_: true

  # æ ¸å¿ƒè·Ÿè¸ªå¥–åŠ± (TWIST é£æ ¼)
  tracking_rewards:
    key_body_position_tracking(KeyBodyPositionTracking):
      weight: 2.0  # TWIST æœ€é‡è¦çš„å¥–åŠ±
      sigma: 0.2
      key_body_names: [".*left.*hand", ".*right.*hand", ".*ankle", ".*knee", ".*elbow", ".*head"]

    joint_position_tracking(JointPositionTracking):
      weight: 0.6
      joint_names: [".*"]
      sigma: 0.2

    joint_velocity_tracking(JointVelocityTracking):
      weight: 0.2
      joint_names: [".*"]
      sigma: 0.2

    root_pose_tracking(RootPoseTracking):
      weight: 0.6
      sigma_pos: 0.2
      sigma_ang: 0.125

    root_velocity_tracking(RootVelocityTracking):
      weight: 1.0
      sigma: 0.2

  # è„šéƒ¨å¥–åŠ±
  feet_rewards:
    feet_air_time(FeetAirTime):
      weight: 5.0
      target_air_time: 0.5
      feet_names: ".*ankle.*"

    feet_slip(FeetSlip):
      weight: -0.1
      feet_names: ".*ankle.*"

    feet_stumble(FeetStumble):
      weight: -1.25
      feet_names: ".*ankle.*"

    feet_contact_forces(FeetContactForces):
      weight: -5e-4
      max_contact_force: 100.0
      feet_names: ".*ankle.*"

  # æ­£åˆ™åŒ–é¡¹
  regularization:
    dof_pos_limits(DofPosLimits):
      weight: -5.0

    dof_vel(DofVel):
      weight: -1e-4

    dof_acc(DofAcc):
      weight: -5e-8

    action_rate(ActionRate):
      weight: -0.01

    ankle_dof_vel(DofVel):
      weight: -2e-4
      joint_names: [".*ankle.*"]

    ankle_dof_acc(DofAcc):
      weight: -1e-7
      joint_names: [".*ankle.*"]

# ==================== Terminations ====================
termination:
  time_out(TimeOut):
    time_out_s: 10.0

  base_contact(BaseContact):
    sensor_name: "contact_forces"
    threshold: 1.0

# ==================== Randomization ====================
randomization:
  # Domain randomization (ä¸ TWIST å¯¹é½)
  gravity_randomization:
    _target_: active_adaptation.envs.mdp.randomizations.GravityRandomization
    interval_s: 4.0
    gravity_range: [-0.1, 0.1]

  friction_randomization:
    _target_: active_adaptation.envs.mdp.randomizations.FrictionRandomization
    friction_range: [0.1, 2.0]

  mass_randomization:
    _target_: active_adaptation.envs.mdp.randomizations.MassRandomization
    added_mass_range: [-3.0, 3.0]

  push_robots:
    _target_: active_adaptation.envs.mdp.randomizations.PushRobots
    interval_s: 4.0
    max_push_vel_xy: 1.0

  motor_strength_randomization:
    _target_: active_adaptation.envs.mdp.randomizations.MotorStrengthRandomization
    strength_range: [0.8, 1.2]
```

---

### Step 5: åˆ›å»ºè®­ç»ƒå¯åŠ¨è„šæœ¬

åˆ›å»º `scripts/train_twist_teacher.sh`:

```bash
#!/bin/bash

# TWIST Teacher Training in HDMI
# Usage: bash scripts/train_twist_teacher.sh experiment_name

EXPTID=${1:-"twist_teacher_$(date +%Y%m%d_%H%M%S)"}
DEVICE=${2:-"cuda:0"}

echo "========================================"
echo "TWIST Teacher Training in HDMI"
echo "Experiment ID: $EXPTID"
echo "Device: $DEVICE"
echo "========================================"

python scripts/train.py \
    algo=ppo_roa_train \
    task=G1/hdmi/twist/twist_teacher \
    total_frames=200_000_000 \
    wandb.project=twist_hdmi \
    wandb.name=$EXPTID \
    wandb.mode=online
```

---

## 5. é…ç½®æ–‡ä»¶å¯¹ç…§

### 5.1 æ ¸å¿ƒå‚æ•°æ˜ å°„

| TWIST | å€¼ | HDMI å¯¹åº” | è¯´æ˜ |
|-------|---|-----------|------|
| `num_envs` | 4096 | `num_envs: 4096` | å¹¶è¡Œç¯å¢ƒæ•° |
| `episode_length_s` | 10 | `max_episode_length: 500` | 10s @ 50Hz |
| `tar_obs_steps` | [1,5,10,...,95] | `future_steps: [1,5,...]` | 20 ä¸ªæœªæ¥æ­¥ |
| `tracking_sigma` | 0.2 | `sigma: 0.2` | Gaussian æ ¸æ ‡å‡†å·® |
| `dt` | 0.002 | `sim.step_dt: 0.002` | ç‰©ç†æ­¥é•¿ |
| `decimation` | 10 | `action_manager.decimation: 10` | æ§åˆ¶é¢‘ç‡ 50Hz |

---

## 6. å®Œæ•´ä»£ç ç¤ºä¾‹

ç”±äºç¯‡å¹…é™åˆ¶ï¼Œå®Œæ•´ä»£ç å·²åˆ†åˆ«åˆ›å»ºåœ¨ï¼š
- `active_adaptation/envs/mdp/observations/twist_observations.py`
- `active_adaptation/envs/mdp/rewards/twist_rewards.py`
- `cfg/task/G1/hdmi/twist/twist_teacher.yaml`

---

## 7. æµ‹è¯•éªŒè¯

### 7.1 è§‚å¯Ÿç©ºé—´éªŒè¯

```python
# æµ‹è¯•è„šæœ¬: test_twist_observations.py
from active_adaptation.utils.helpers import make_env

env = make_env("G1/hdmi/twist/twist_teacher")

# æ£€æŸ¥è§‚å¯Ÿç»´åº¦
policy_obs = env.observation_spec["policy_obs"]
critic_obs = env.observation_spec["critic_obs"]

print(f"Policy obs shape: {policy_obs.shape}")
print(f"Critic obs shape: {critic_obs.shape}")

# é¢„æœŸ:
# Policy: n_proprio(80) + n_mimic(1160) = 1240
# Critic: n_proprio(80) + n_mimic(1160) + n_priv(85) = 1325
```

### 7.2 å¥–åŠ±æƒé‡éªŒè¯

```bash
# è®­ç»ƒ 1000 æ­¥ï¼Œæ£€æŸ¥å¥–åŠ±åˆ†å¸ƒ
python scripts/train.py \
    algo=ppo_roa_train \
    task=G1/hdmi/twist/twist_teacher \
    total_frames=1000 \
    wandb.mode=disabled
```

æ£€æŸ¥è¾“å‡ºä¸­çš„å¥–åŠ±ç»Ÿè®¡ï¼Œç¡®ä¿ï¼š
- `key_body_position_tracking` æƒé‡æœ€é«˜
- å„é¡¹æ­£åˆ™åŒ–æƒ©ç½šæ­£å¸¸å·¥ä½œ

---

## 8. å¸¸è§é—®é¢˜

### Q1: è§‚å¯Ÿç»´åº¦ä¸åŒ¹é…

**ç°è±¡**: `RuntimeError: size mismatch, expected 1325, got 1240`

**è§£å†³**: æ£€æŸ¥ `critic_obs` æ˜¯å¦åŒ…å« `PrivilegedInfo`

---

### Q2: Motion æ•°æ®æ ¼å¼é”™è¯¯

**ç°è±¡**: `KeyError: 'local_body_pos'`

**è§£å†³**: ç¡®ä¿ TWIST motion pkl æ–‡ä»¶åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ

---

### Q3: å…³é”®ç‚¹ç´¢å¼•é”™è¯¯

**ç°è±¡**: æ‰¾ä¸åˆ° "left_rubber_hand"

**è§£å†³**: æ£€æŸ¥ URDF ä¸­çš„ body åç§°ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ `key_body_names` çš„æ­£åˆ™è¡¨è¾¾å¼

---

## 9. æ€§èƒ½ä¼˜åŒ–

### 9.1 å†…å­˜ä¼˜åŒ–

TWIST ä½¿ç”¨ 20 ä¸ªæœªæ¥æ­¥ï¼Œå†…å­˜å ç”¨è¾ƒå¤§ã€‚å¯ä»¥è€ƒè™‘ï¼š

```python
# ä½¿ç”¨ memory-mapped tensors
dataset = TwistMotionDataset.create_from_yaml(
    yaml_path=data_path,
    device=device,
    memory_mapped=True  # å‡å°‘æ˜¾å­˜å ç”¨
)
```

### 9.2 è®¡ç®—ä¼˜åŒ–

```python
# åœ¨è§‚å¯Ÿå‡½æ•°ä¸­ä½¿ç”¨ç¼–è¯‘ä¼˜åŒ–
@torch.compile(mode="reduce-overhead")
def _compute_multi_step_reference(self):
    # ... è§‚å¯Ÿè®¡ç®—é€»è¾‘
```

---

## 10. æ€»ç»“

### âœ… å·²å®Œæˆ
1. âœ… `TwistMotionDataset` - Motion æ•°æ®åŠ è½½
2. âœ… `TwistMotionData` - æ•°æ®ç»“æ„

### ğŸš§ éœ€è¦å®ç°
1. ğŸš§ `MultiStepReferenceTracking` è§‚å¯Ÿ
2. ğŸš§ `KeyBodyPositionTracking` å¥–åŠ±
3. ğŸš§ `FeetAirTime` å¥–åŠ±
4. ğŸš§ å®Œæ•´çš„ TWIST ä»»åŠ¡é…ç½®

### ğŸ“Š é¢„æœŸæ•ˆæœ
- è§‚å¯Ÿç»´åº¦: ä¸ TWIST å®Œå…¨ä¸€è‡´
- å¥–åŠ±å‡½æ•°: ä¸ TWIST å®Œå…¨å¯¹é½
- è®­ç»ƒæ€§èƒ½: ç›¸å½“äº TWIST Teacher è®­ç»ƒ

---

## 11. ä¸‹ä¸€æ­¥è¡ŒåŠ¨

æŒ‰ä»¥ä¸‹é¡ºåºæ‰§è¡Œï¼š

1. **åˆ›å»ºè§‚å¯Ÿå‡½æ•°** â†’ `twist_observations.py`
2. **åˆ›å»ºå¥–åŠ±å‡½æ•°** â†’ `twist_rewards.py`
3. **åˆ›å»ºä»»åŠ¡é…ç½®** â†’ `twist_teacher.yaml`
4. **æµ‹è¯•è§‚å¯Ÿç©ºé—´** â†’ éªŒè¯ç»´åº¦
5. **æµ‹è¯•å¥–åŠ±å‡½æ•°** â†’ éªŒè¯æƒé‡
6. **å¼€å§‹è®­ç»ƒ** â†’ `bash scripts/train_twist_teacher.sh`

é¢„è®¡æ€»å·¥ä½œé‡: **2-3 å¤©**
